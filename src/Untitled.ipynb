{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbe56fb-00f7-448a-91cb-441fd2185c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic\n",
    "%pycodestyle_on\n",
    "# %pycodestyle_off -to turn it off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54cb767a-7b5a-4cba-b24d-0ae3feded6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from minio import Minio\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_timestamp, month, year,monotonically_increasing_id,row_number,concat, udf,lit\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType, LongType,TimestampNTZType,StringType\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.conf import SparkConf\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from binance import Client\n",
    "from datetime import datetime, date\n",
    "import os\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "from binance.helpers import date_to_milliseconds, interval_to_milliseconds\n",
    "from binance.exceptions import BinanceRequestException, BinanceAPIException\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from dateutil.parser import parse\n",
    "import time\n",
    "import logging\n",
    "import psycopg2\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e599f2a-a8c2-4d5b-8acc-6550f36bd0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "SECRET_KEY = os.getenv(\"SECRET_KEY\")\n",
    "MINIO_USER = os.getenv(\"MINIO_ROOT_USER\")\n",
    "MINIO_PASSWORD = os.getenv(\"MINIO_ROOT_PASSWORD\")\n",
    "client_binance = Client(API_KEY, SECRET_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4023de86-2b14-4e29-90e0-64a949ce864c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/25 11:32:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CryptoETL\") \\\n",
    "    .config(\"spark.jars\", \"/Users/hamza/Desktop/projects/postgresql-42.7.5.jar\") \\\n",
    "    .getOrCreate()\n",
    "# Get the SparkContext from the SparkSession\n",
    "sc = spark.sparkContext\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", MINIO_USER)#turn into access key in the future \n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", MINIO_PASSWORD)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"http://localhost:9000\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.connection.ssl.enabled\", \"true\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.path.style.access\", \"true\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.attempts.maximum\", \"1\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.connection.establish.timeout\", \"5000\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.connection.timeout\", \"10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fe1b0bb-56a4-438f-8801-796b493aaefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data for 1 crypto\n",
    "#schema check/validation need to do this, create spark df using schema struct\n",
    "#implement transformations\n",
    "#add unique id for crypto,price,time\n",
    "#split into 3 tables\n",
    "#upload to postgres db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457ad682-a432-4de4-b526-4331b68563fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG) #set to debug to capture all levels\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "logger.propagate = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847fe01e-ba2f-417d-8d7e-41fbfaffedfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = logging.StreamHandler()\n",
    "handler.setLevel(logging.DEBUG)\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5dce917-2573-401d-918a-13f4bd641df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/25 11:32:48 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "cryptos = ['BTCUSDT','ETHUSDT','LTCUSDT','BNBUSDT','DOGEUSDT'] #consider improving maintainability\n",
    "client_minio = Minio(\n",
    "        \"localhost:9000\",  # Make sure you're using port 9000 for the S3 API\n",
    "        #minio_url,\n",
    "        access_key = MINIO_USER,\n",
    "        secret_key = MINIO_PASSWORD,\n",
    "        secure=False  # Disable SSL if you're not using SSL certificates\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88a7244c-82a4-468f-b6ae-c44317cdf68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\\\n",
    "                    StructField(name = 'datetime',dataType = TimestampNTZType(),nullable = False), \\\n",
    "                    StructField(name= 'Open Price',dataType = LongType(),nullable =False), \\\n",
    "                    StructField(name= 'Close Price',dataType = LongType(),nullable =False), \\\n",
    "                    StructField(name= 'Volume',dataType = LongType(),nullable = False)\\\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "551881aa-3f3d-4b52-9b14-c8e60f202243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parquet_to_df(client,crypto,schema):\n",
    "    #read from parquet from minio and combines into dataframe\n",
    "    objects = client.list_objects(\"binancedata\", prefix=crypto, recursive=True)\n",
    "    filenames = [obj.object_name for obj in objects]\n",
    "    filenames = [f for f in filenames if \"_SUCCESS\" not in f]\n",
    "    df = spark.createDataFrame(data = [],schema = schema)\n",
    "    for file in filenames:\n",
    "        df_parquet = spark.read.parquet(f\"s3a://binancedata/{file}\")\n",
    "        df = df.union(df_parquet)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57486214-bb03-4e29-b0ab-835f59da981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning():\n",
    "    pass\n",
    "    #drop duplicates\n",
    "    #convert data types\n",
    "    #drop null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5852cf9-c1f9-4fcd-87d5-f5ddbf52f783",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_sql = \"SELECT * FROM crypto\"\n",
    "\n",
    "df_crypto = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://localhost:5432/crypto\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"postgres\") \\\n",
    "    .option(\"query\", read_sql)\\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\")\\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3548c7cc-f862-44fc-a751-fbd49c1ef4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_crypto_id(df_crypto,crypto,currency):\n",
    "    df_crypto = df_crypto.withColumn(\"trading pair\", concat(df_crypto.ticker, lit(currency)))\n",
    "    #obtain the crypto from concatenating currency and ticker\n",
    "    df_crypto = df_crypto.filter(col(\"trading pair\") == crypto)\n",
    "    crypto_id = df_crypto.collect()[0]['id']\n",
    "    df_id = df.withColumn(\"crypto_id\",lit(crypto_id))\n",
    "    return df_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ae3dc860-b03f-42a9-a75f-20ea3e32cfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_id(dt_value):\n",
    "    #hard coded\n",
    "    ts = dt_value.strftime(\"%Y%m\")\n",
    "    return int(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bbe5943a-5e0b-4fc3-9a3a-ac227dcdad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_id(generate_time_id,df):\n",
    "    dt_udf = udf(generate_time_id,IntegerType())\n",
    "    df_with_udf = df.withColumn(\"time_id\", dt_udf(df[\"datetime\"]))\n",
    "    #df_time = df_time.withColumnRenamed('time_id','id')\n",
    "    return df_with_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d466e74b-1c2e-4004-9df7-f75f1e2f3824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_time(df):\n",
    "    #need to futureproof\n",
    "    df_year = df.withColumn(\"year\", year(df[\"datetime\"]))\n",
    "    df_month = df_year.withColumn(\"month\", month(df_year[\"datetime\"]))\n",
    "    df_time_filtered = df_month.select(['time_id','datetime','year','month'])\n",
    "    df_time = df_time_filtered.withColumnRenamed('time_id','id')\n",
    "    try:\n",
    "        df_time.write \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:postgresql://localhost:5432/crypto\") \\\n",
    "        .option(\"dbtable\", \"time\") \\\n",
    "        .option(\"user\", \"postgres\") \\\n",
    "        .option(\"password\", \"postgres\") \\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "        .mode(\"append\")\\\n",
    "        .save()\n",
    "        print(\"successfully uploaded to time table\")\n",
    "    except Exception as e:\n",
    "        #logger.error(e,stack_info=True,exc_info=True)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e7f8a23b-7a36-4da4-8e56-8f6c4c843aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parquet_to_df(client_minio,\"BNBUSDT\",schema)\n",
    "df_id = add_crypto_id(df_crypto,\"BNBUSDT\",\"USDT\")\n",
    "df_time_id =add_time_id(generate_time_id,df_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d788e407-528d-4b1f-bef0-6f16e223774a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+-----------+------------------+---------+-------+\n",
      "|           datetime| Open Price|Close Price|            Volume|crypto_id|time_id|\n",
      "+-------------------+-----------+-----------+------------------+---------+-------+\n",
      "|2019-01-01 00:00:00| 6.11390000| 6.22000000| 72126339.77000000|        5| 201901|\n",
      "|2019-10-01 01:00:00|15.84930000|19.90990000| 53481014.91000000|        5| 201910|\n",
      "|2019-11-01 00:00:00|19.90870000|15.71180000| 46441747.10000000|        5| 201911|\n",
      "|2019-12-01 00:00:00|15.70300000|13.71610000| 38189582.55000000|        5| 201912|\n",
      "|2019-02-01 00:00:00| 6.22500000|10.27790000|110685041.86000000|        5| 201902|\n",
      "+-------------------+-----------+-----------+------------------+---------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_time_id.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "64ddf15b-a585-48a6-8d9d-406de9d0ff9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully uploaded to time table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "upload_time(df_time_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "85e824ee-69ad-4682-ad24-de25ef5a2f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_price(df):\n",
    "    df_filtered = df.select(['crypto_id','time_id','Open Price','Close Price','Volume'])\n",
    "    df_rename = df_filtered.withColumnsRenamed({'Open Price':'open',\n",
    "                            'Close Price':'close',\n",
    "                            'Volume':'volume'}\n",
    "                           )\n",
    "    df_rename = df_rename.withColumn(\"open\",df_rename.open.cast(IntegerType()))\n",
    "    df_rename = df_rename.withColumn(\"close\",df_rename.close.cast(IntegerType()))\n",
    "    df_rename = df_rename.withColumn(\"volume\",df_rename.volume.cast(IntegerType()))\n",
    "    \n",
    "    try:\n",
    "        df_rename.write \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:postgresql://localhost:5432/crypto\") \\\n",
    "        .option(\"dbtable\", \"price\") \\\n",
    "        .option(\"user\", \"postgres\") \\\n",
    "        .option(\"password\", \"postgres\") \\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "        .mode(\"append\")\\\n",
    "        .save()\n",
    "        print(\"successfully uploaded to price table\")\n",
    "    except Exception as e:\n",
    "        #logger.error(e,stack_info=True,exc_info=True)\n",
    "        print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "00c87cd6-70a5-4256-b64f-12bb3c05fd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/25 15:33:13 WARN DAGScheduler: Broadcasting large task binary with size 1000.5 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully uploaded to price table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "upload_price(df_time_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7ac00b-006e-4733-b067-7d9f0f0de71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply functional programming\n",
    "#time is universal so dont need to readd\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
