{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbe56fb-00f7-448a-91cb-441fd2185c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic\n",
    "%pycodestyle_on\n",
    "# %pycodestyle_off -to turn it off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54cb767a-7b5a-4cba-b24d-0ae3feded6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from minio import Minio\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession,DataFrame as SparkDataFrame\n",
    "from pyspark.sql.functions import col, to_timestamp, month, year,monotonically_increasing_id,row_number,concat, udf,lit\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType, LongType,TimestampNTZType,StringType,DecimalType\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.conf import SparkConf\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from binance import Client\n",
    "from datetime import datetime, date\n",
    "import os\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "from binance.helpers import date_to_milliseconds, interval_to_milliseconds\n",
    "from binance.exceptions import BinanceRequestException, BinanceAPIException\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from dateutil.parser import parse\n",
    "import time\n",
    "import logging\n",
    "import psycopg2\n",
    "import typing\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e599f2a-a8c2-4d5b-8acc-6550f36bd0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "SECRET_KEY = os.getenv(\"SECRET_KEY\")\n",
    "MINIO_USER = os.getenv(\"MINIO_ROOT_USER\")\n",
    "MINIO_PASSWORD = os.getenv(\"MINIO_ROOT_PASSWORD\")\n",
    "client_binance = Client(API_KEY, SECRET_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4023de86-2b14-4e29-90e0-64a949ce864c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/05 19:07:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CryptoETL\") \\\n",
    "    .config(\"spark.jars\", \"/Users/hamza/Desktop/projects/postgresql-42.7.5.jar\") \\\n",
    "    .getOrCreate()\n",
    "# Get the SparkContext from the SparkSession\n",
    "sc = spark.sparkContext\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", MINIO_USER)#turn into access key in the future \n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", MINIO_PASSWORD)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"http://localhost:9000\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.connection.ssl.enabled\", \"true\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.path.style.access\", \"true\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.attempts.maximum\", \"1\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.connection.establish.timeout\", \"5000\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.connection.timeout\", \"10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "457ad682-a432-4de4-b526-4331b68563fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG) #set to debug to capture all levels\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "logger.propagate = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "847fe01e-ba2f-417d-8d7e-41fbfaffedfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = logging.StreamHandler()\n",
    "handler.setLevel(logging.DEBUG)\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5dce917-2573-401d-918a-13f4bd641df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cryptos = ['BTCUSDT','ETHUSDT','LTCUSDT','BNBUSDT','DOGEUSDT'] #consider improving maintainability\n",
    "client_minio = Minio(\n",
    "        \"localhost:9000\",  # Make sure you're using port 9000 for the S3 API\n",
    "        #minio_url,\n",
    "        access_key = MINIO_USER,\n",
    "        secret_key = MINIO_PASSWORD,\n",
    "        secure=False  # Disable SSL if you're not using SSL certificates\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a7244c-82a4-468f-b6ae-c44317cdf68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\\\n",
    "                    StructField(name = 'datetime',dataType = TimestampNTZType(),nullable = False), \\\n",
    "                    StructField(name= 'Open Price',dataType = DecimalType(),nullable =False), \\\n",
    "                    StructField(name= 'Close Price',dataType = DecimalType(),nullable =False), \\\n",
    "                    StructField(name= 'Volume',dataType = DecimalType(),nullable = False)\\\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48e4a4d9-bc7b-44fc-b0c8-1de99aaeb73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parquet_to_df(client,crypto,schema):\n",
    "    #read from parquet from minio and combines into dataframe\n",
    "    try:\n",
    "        objects = client.list_objects(\"binancedata\", prefix=f\"{crypto}/Daily\", recursive=True)\n",
    "        filenames = [obj.object_name for obj in objects]\n",
    "        filenames = [f for f in filenames if \"_SUCCESS\" not in f]\n",
    "        df = spark.createDataFrame(data = [],schema = schema)\n",
    "        for file in filenames:\n",
    "            df_parquet = spark.read.parquet(f\"s3a://binancedata/{file}\")\n",
    "            df = df.union(df_parquet)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"error reading parquet from minio: {e}\", stack_info=True, exc_info=True)\n",
    "\n",
    "def data_cleaning(df):\n",
    "    try:\n",
    "        df_null = df.na.drop(how = 'any',subset = ['datetime'])\n",
    "        df_renamed = df_null.withColumnsRenamed({'Open Price':'open',\n",
    "                                'Close Price':'close',\n",
    "                                'Volume':'volume'})\n",
    "        df_duplicated = df_renamed.dropDuplicates()\n",
    "        df_duplicated = df_duplicated.withColumn(\"open\", col(\"open\").cast(DecimalType(10, 5))) \\\n",
    "                             .withColumn(\"close\", col(\"close\").cast(DecimalType(10, 5))) \\\n",
    "                             .withColumn(\"volume\", col(\"volume\").cast(DecimalType(20, 5)))\n",
    "\n",
    "        return df_duplicated\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error cleaning data:{e}\",stack_info=True,exc_info=True)\n",
    "        \n",
    "read_sql = \"SELECT * FROM crypto\"\n",
    "df_crypto = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://postgres1:5432/crypto\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"postgres\") \\\n",
    "    .option(\"query\", read_sql)\\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\")\\\n",
    "    .load()\n",
    "\n",
    "def parquet_to_df(client,crypto,schema):\n",
    "    #read from parquet from minio and combines into dataframe\n",
    "    try:\n",
    "        objects = client.list_objects(\"binancedata\", prefix=f\"{crypto}/Daily\", recursive=True)\n",
    "        filenames = [obj.object_name for obj in objects]\n",
    "        filenames = [f for f in filenames if \"_SUCCESS\" not in f]\n",
    "        df = spark.createDataFrame(data = [],schema = schema)\n",
    "        for file in filenames:\n",
    "            df_parquet = spark.read.parquet(f\"s3a://binancedata/{file}\")\n",
    "            df = df.union(df_parquet)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"error reading parquet from minio: {e}\", stack_info=True, exc_info=True)\n",
    "\n",
    "def data_cleaning(df):\n",
    "    try:\n",
    "        df_null = df.na.drop(how = 'any',subset = ['datetime'])\n",
    "        df_renamed = df_null.withColumnsRenamed({'Open Price':'open',\n",
    "                                'Close Price':'close',\n",
    "                                'Volume':'volume'})\n",
    "        df_duplicated = df_renamed.dropDuplicates()\n",
    "        df_duplicated = df_duplicated.withColumn(\"open\", col(\"open\").cast(DecimalType(10, 5))) \\\n",
    "                             .withColumn(\"close\", col(\"close\").cast(DecimalType(10, 5))) \\\n",
    "                             .withColumn(\"volume\", col(\"volume\").cast(DecimalType(20, 5)))\n",
    "\n",
    "        return df_duplicated\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error cleaning data:{e}\",stack_info=True,exc_info=True)\n",
    "        \n",
    "\n",
    "def add_crypto_id(df,df_crypto,crypto,currency):\n",
    "    try:\n",
    "        df_crypto = df_crypto.withColumn(\"trading pair\", concat(df_crypto.ticker, lit(currency)))\n",
    "        #obtain the crypto from concatenating currency and ticker\n",
    "        df_crypto = df_crypto.filter(col(\"trading pair\") == crypto)\n",
    "        crypto_id = df_crypto.collect()[0]['id']\n",
    "        df_id = df.withColumn(\"crypto_id\",lit(crypto_id))\n",
    "        return df_id\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error adding crypto id:{e}\",stack_info=True,exc_info=True)\n",
    "    return df_id\n",
    "\n",
    "def generate_time_id(dt_value):\n",
    "    #hard coded\n",
    "    ts = dt_value.strftime(\"%Y%m%d\")\n",
    "    return int(ts)\n",
    "\n",
    "def add_time_id(generate_time_id,df):\n",
    "    try:\n",
    "        dt_udf = udf(generate_time_id,IntegerType())\n",
    "        df_with_udf = df.withColumn(\"time_id\", dt_udf(df[\"datetime\"]))\n",
    "        #df_time = df_time.withColumnRenamed('time_id','id')\n",
    "        return df_with_udf\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error adding time id:{e}\",stack_info=True,exc_info=True)\n",
    "\n",
    "def upload_time(df):\n",
    "    #need to futureproof\n",
    "    df_year = df.withColumn(\"year\", year(df[\"datetime\"]))\n",
    "    df_month =df_year.withColumn(\"month\", month(df_year[\"datetime\"]))\n",
    "    df_day = df_month.withColumn(\"day\", day(df_month[\"datetime\"]))\n",
    "    df_time_filtered = df_day.select(['time_id','datetime','year','month','day'])\n",
    "    df_time = df_time_filtered.withColumnRenamed('time_id','id')\n",
    "    try:\n",
    "        df_time.write \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:postgresql://postgres1:5432/crypto\") \\\n",
    "        .option(\"dbtable\", \"time\") \\\n",
    "        .option(\"user\", \"postgres\") \\\n",
    "        .option(\"password\", \"postgres\") \\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "        .mode(\"append\")\\\n",
    "        .save()\n",
    "        logger.info(\"Successfully uploaded to time table\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error uploading to time table:{e}\",stack_info=True,exc_info=True)\n",
    "\n",
    "def upload_price(df):\n",
    "    df_filtered = df.select(['crypto_id','time_id','open','close','volume'])\n",
    "    logger.info(df_filtered.show(5))\n",
    "    try:\n",
    "        df_filtered.write \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:postgresql://postgres1:5432/crypto\") \\\n",
    "        .option(\"dbtable\", \"price\") \\\n",
    "        .option(\"user\", \"postgres\") \\\n",
    "        .option(\"password\", \"postgres\") \\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "        .mode(\"append\")\\\n",
    "        .save()\n",
    "        logger.info(\"Successfully uploaded to price table\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error uploading to price table:{e}\",stack_info=True,exc_info=True)\n",
    "        \n",
    "def monthly_transform(symbol,currency):\n",
    "    df = parquet_to_df(client = client_minio,crypto = symbol,schema = schema)\n",
    "    df_cleaned = data_cleaning(df)\n",
    "    df_id = add_crypto_id(df_cleaned,df_crypto,symbol,currency)\n",
    "    df_time_id =add_time_id(generate_time_id,df_id)\n",
    "    logger.info(df_time_id.show())\n",
    "    upload_time(df_time_id)\n",
    "    upload_price(df_time_id)\n",
    "    logger.info(f\"Data successfully transformed and loaded for {symbol}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3df238-f46e-4f9e-a6e1-e0adbaa96ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec5389f6-6f08-4926-9afe-e8d10d6828d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_sql = \"SELECT * FROM crypto\"\n",
    "df_crypto = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://localhost:5432/crypto\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"postgres\") \\\n",
    "    .option(\"query\", read_sql)\\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\")\\\n",
    "    .load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e12c856-59c4-46de-9ad8-f8916d4be426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/05 19:08:49 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n"
     ]
    }
   ],
   "source": [
    "df = parquet_to_df(client = client_minio,crypto = \"BNBUSDT\",schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57a8b016-2802-4801-a5b6-283c46e9fb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = data_cleaning(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7e92533-ce26-4c5d-a713-426c3c923567",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = add_crypto_id(df_cleaned,df_crypto,\"BNBUSDT\",\"USDT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "697d89c7-4426-40bd-b0ee-e29fd7f27082",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_id =add_time_id(generate_time_id,df_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56de2dc8-d610-4a52-bef9-ece12d49d430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+-------+-------------+---------+--------+\n",
      "|           datetime|   open|  close|       volume|crypto_id| time_id|\n",
      "+-------------------+-------+-------+-------------+---------+--------+\n",
      "|2019-01-24 00:00:00|6.49630|6.45880|1514319.91000|        5|20190124|\n",
      "|2019-01-27 00:00:00|6.94530|7.03960|2776887.68000|        5|20190127|\n",
      "|2019-01-07 00:00:00|6.26810|6.20090|1683858.68000|        5|20190107|\n",
      "|2019-01-16 00:00:00|5.80070|6.09110|2164639.90000|        5|20190116|\n",
      "|2019-01-30 00:00:00|6.13350|6.13880|2238811.59000|        5|20190130|\n",
      "+-------------------+-------+-------+-------------+---------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_time_id.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11e8ff44-45ea-43e4-be28-88d9b11a2f92",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (1815136773.py, line 29)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[13], line 29\u001b[0;36m\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns = [\n",
    "    \"Kline open time\",\n",
    "    \"Open Price\",\n",
    "    \"High price\",\n",
    "    \"Low price\",\n",
    "    \"Close Price\",\n",
    "    \"Volume\",\n",
    "    \"Kline Close time\",\n",
    "    \"Quote asset volume\",\n",
    "    \"Number of trades\",\n",
    "    \"Taker buy base asset volume\",\n",
    "    \"Taker buy quote asset volume\",\n",
    "    \"Ignore\",\n",
    "]\n",
    "\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7381b320-e4ca-4f03-b5c8-069f70e7555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_price(df):\n",
    "    \"\"\"\n",
    "    Uploads dataframe to price table\n",
    "\n",
    "    \"\"\"\n",
    "    df_filtered = df.select(['crypto_id','time_id','open','close','volume'])\n",
    "    logger.info(df_filtered.show(5))\n",
    "    try:\n",
    "        df_filtered.write \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:postgresql://postgres1:5432/crypto\") \\\n",
    "        .option(\"dbtable\", \"price\") \\\n",
    "        .option(\"user\", \"postgres\") \\\n",
    "        .option(\"password\", \"postgres\") \\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "        .mode(\"append\")\\\n",
    "        .save()\n",
    "        logger.info(\"Successfully uploaded to price table\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error uploading to price table:{e}\",stack_info=True,exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e1be835-e47a-4861-ab2e-614f5f020e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(generate_time_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a2ff75-9ba5-4fd5-99c2-f84b468daaf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
